# ðŸ—žï¸ Clawler

**Advanced news crawling service** â€” no API keys required.

Clawler aggregates news from **250+ individual sources across 44 source types** using RSS feeds, APIs, and web scraping. It deduplicates stories with quality-aware selection and ranks them by a blend of recency and source quality.

## Features

- ðŸ“¡ **250+ sources across 44 source types** â€” 54 RSS feeds, Hacker News API, Reddit (21 subreddits), GitHub Trending, Mastodon (4 instances), Lobsters, Wikipedia Current Events, Dev.to, ArXiv, TechMeme, ProductHunt, Bluesky, Tildes, Lemmy (3 instances), Slashdot, Stack Overflow, Pinboard Popular, Indie Hackers, EchoJS, Hashnode (6 topic feeds), freeCodeCamp, Changelog, Hacker Noon, YouTube (22 channels), Medium (20 tags + 10 publications), Google News (5 topics + 8 searches), DZone (12 topic feeds), ScienceDaily (7 section feeds), NPR (10 section feeds), Ars Technica (10 section feeds), AllTop (33 topic categories), Wired (6 section feeds), The Verge, AP News (10 section feeds), The Guardian (10 section feeds), InfoQ (7 topic feeds), The Register (7 section feeds), BBC News (10 section feeds), The Hacker News (cybersecurity)
- ðŸ”‘ **No API keys** â€” works out of the box with public feeds and endpoints
- ðŸ§¹ **Smart deduplication** â€” 3-tier: exact hash, fingerprint, fuzzy title; keeps higher-quality source
- âš–ï¸ **Quality weighting** â€” sources scored on credibility, uniqueness, signal-to-noise, freshness, reliability, coverage
- ðŸ“Š **Multiple output formats** â€” Console, JSON, **JSONL**, JSON Feed, Atom, Markdown, CSV, HTML
- ðŸ·ï¸ **Category filtering** â€” tech, world, science, business, security, investigative, culture
- âš¡ **Parallel crawling** â€” concurrent fetching across all sources
- ðŸ©º **Health tracking** â€” per-source success rates with automatic score reduction
- ðŸ“¥ **OPML import/export** â€” bring your own feed lists
- ðŸ“¤ **Feed export** â€” export feed list as YAML (`--export-feeds`)
- ðŸ” **Feed discovery** â€” auto-detect feeds on any URL
- ðŸŽ¯ **Interest profiles** â€” relevance scoring based on personal interests
- ðŸ“¦ **Result caching** â€” skip network if results are fresh
- ðŸ”¥ **Cross-source tracking** â€” see how many sources covered the same story
- ðŸ“‚ **Group-by output** â€” group results by category or source
- ðŸ”„ **Reverse sort** â€” flip any sort order
- ðŸ©º **Source health report** â€” `--source-health` for per-source success rates and article counts
- âš™ï¸ **Config generator** â€” `--config-init` creates a starter `~/.clawler.yaml`
- ðŸ” **CI pipeline** â€” GitHub Actions runs tests on Python 3.9â€“3.12
- ðŸ›¡ï¸ **Error resilient** â€” individual source failures don't break the crawl
- ðŸš¦ **Rate limiting** â€” per-domain request throttling to be a good citizen
- ðŸ“š **Bookmarks** â€” save interesting articles locally for later reading
- ðŸ“Š **Dedup statistics** â€” see per-tier dedup breakdown with `--dedupe-stats`
- ðŸ”¥ **Trending shorthand** â€” `--trending` for multi-source stories
- ðŸ”— **Pipe-friendly output** â€” `--urls-only` and `--titles-only` for scripting
- ðŸš« **Dedup bypass** â€” `--no-dedup` to see all raw articles
- ðŸŒ **Domain breakdown** â€” `--domains` for domain-level analytics
- ðŸ•°ï¸ **Persistent dedup history** â€” `--history` remembers seen articles across runs (perfect for cron)
- ðŸŒ **Environment variable config** â€” `CLAWLER_*` env vars for containerized/CI usage
- ðŸ”‡ **Auto-quiet when piped** â€” suppresses stderr noise when output is piped
- ðŸŽ² **Random sampling** â€” `--sample N` for serendipitous discovery
- ðŸ“¦ **Compact JSON** â€” `--json-compact` for minified single-line JSON
- â±ï¸ **Reading time estimation** â€” `--show-read-time` displays estimated read time; `--min-read`/`--max-read` to filter by duration
- ðŸŽ¨ **NO_COLOR support** â€” `--no-color` or `NO_COLOR=1` env var
- ðŸ’¬ **Discussion URLs** â€” structured `discussion_url` field on articles (HN, Lobsters, Reddit)
- ðŸ“‹ **Source list** â€” `--source-list` shows all configured sources with types and quality weights
- ðŸ”— **Show discussions** â€” `--show-discussions` to include discussion links in console output
- ðŸ“„ **ArXiv source** â€” recent CS/AI/ML/physics papers from arXiv's public API (`--no-arxiv` to skip)
- ðŸ“° **TechMeme source** â€” curated tech news river (`--no-techmeme` to skip)
- ðŸš€ **ProductHunt source** â€” trending products (`--no-producthunt` to skip)
- ðŸ¦‹ **Bluesky source** â€” trending shared links from the AT Protocol network (`--no-bluesky` to skip)
- ðŸ›ï¸ **Tildes source** â€” quality discussion community topics from tildes.net (`--no-tildes` to skip)
- ðŸ **Lemmy source** â€” trending posts from Fediverse link aggregator instances (`--no-lemmy` to skip)
- ðŸ’¾ **Slashdot source** â€” classic tech news and discussion from Slashdot RSS (`--no-slashdot` to skip)
- ðŸ”¶ **Stack Overflow source** â€” hot questions from Stack Overflow's public API (`--no-stackoverflow` to skip)
- ðŸ“Œ **Pinboard Popular source** â€” trending community-curated bookmarks from pinboard.in (`--no-pinboard` to skip)
- ðŸš€ **Indie Hackers source** â€” trending posts from the bootstrapper/indie maker community (`--no-indiehackers` to skip)
- ðŸ“… **`--since today/this-week/this-month`** â€” named time periods relative to current calendar boundaries
- ðŸš« **`--exclude-domain`** â€” filter out articles from specific domains (comma-separated)
- âš¡ **Fresh mode** â€” `--fresh` shorthand for `--since 1h`
- ðŸ“… **ISO date support** â€” `--since 2026-02-14` or `--since 2026-02-14T10:00:00Z` for absolute time filters
- ðŸ”— **Smarter URL dedup** â€” normalizes `www.` prefixes and trailing slashes for better duplicate detection
- ðŸ” **The Hacker News source** â€” cybersecurity news with auto-classification of vulnerabilities, malware, and breaches (`--no-thehackernews` to skip)
- ðŸ“° **AP News source** â€” trusted wire service, 10 section feeds (`--no-apnews` to skip)
- ðŸ›ï¸ **The Guardian source** â€” quality UK/world journalism, 10 section feeds (`--no-guardian` to skip)
- ðŸ““ **Wired source** â€” premium tech/science/security journalism from 6 section feeds (`--no-wired` to skip)
- ðŸ“± **The Verge source** â€” major tech publication with auto-categorization (`--no-theverge` to skip)
- ðŸŒ **Language detection & filtering** â€” `--lang en,es` to keep specific languages; `--exclude-lang zh` to exclude; lightweight heuristic detection (12 languages, no dependencies)
- ðŸŽ¨ **`--json-pretty`** â€” pretty-printed JSON output with 4-space indentation
- âš™ï¸ **Full config file support** â€” all 21 source toggles, `lang`, `exclude_lang`, `exclude_domain`, `min_relevance`, `min_quality`, `cache_ttl`, `retries`, `sample` now configurable via `~/.clawler.yaml` or `CLAWLER_*` env vars
- ðŸ” **Source-level retry** â€” failed sources are retried with exponential backoff (`--source-retries N`, `--no-retry`)
- ðŸ“… **Named time periods** â€” `--since yesterday`, `--since last-week`, `--since last-month`, `--since last-year`
- ðŸ“¤ **Export health as JSON** â€” `--export-health FILE` for machine-readable source health data
- ðŸš« **Exclude filters** â€” `--exclude-tag` and `--exclude-author` for precise result trimming
- â±ï¸ **Age statistics** â€” `--age-stats` shows min/max/avg/median article age
- ðŸ“¡ **Top sources analytics** â€” `--top-sources` shows which sources contributed the most articles
- ðŸ·ï¸ **Top tags analytics** â€” `--top-tags` shows the most common tags across results
- âœï¸ **Top authors analytics** â€” `--top-authors` shows the most prolific authors across results
- ðŸ“ **Top words analytics** â€” `--top-words` shows the most common words in article titles (stop words excluded)
- âš–ï¸ **Source quality breakdown** â€” `--source-quality` shows average quality score per source with article counts
- ðŸŽ¯ **`--only` source filter** â€” `--only rss,hn` enables only those sources (cleaner than disabling everything else)
- â±ï¸ **Crawl timing** â€” total crawl time shown on stderr after each run
- ðŸ“„ **`--json-lines` alias** â€” discoverable alias for `-f jsonl`
- ðŸ“š **freeCodeCamp source** â€” developer tutorials and articles from freeCodeCamp.org (`--no-freecodecamp` to skip)
- ðŸ“° **Digest mode** â€” `--digest` shorthand for `--since 24h --group-by category --sort quality --format markdown`
- ðŸŽ­ **Tone filtering** â€” `--tone positive/negative/neutral` for sentiment-based filtering
- ðŸš« **No-doom mode** â€” `--no-doom` to exclude strongly negative/doom articles
- ðŸ“° **Changelog source** â€” developer news and podcasts from changelog.com (`--no-changelog` to skip)
- ðŸ“‚ **Category stats** â€” `--category-stats` shows article count per category with percentages
- ðŸŽ¯ **Profile generator** â€” `--profile-init` creates a starter interest profile YAML


## Quick Start

```bash
git clone https://github.com/clawdiard/clawler.git
cd clawler
pip install -e .
clawler
```

## Docker

```bash
docker build -t clawler .
docker run --rm clawler                          # default: top 50 stories
docker run --rm clawler --category tech -n 20    # tech news, top 20
docker run --rm clawler -f json | jq '.[0]'      # JSON output
```

## Usage

```bash
# Default: rich console output, top 50 stories
clawler

# JSON output for piping
clawler -f json

# JSON Lines output (one JSON object per line â€” great for streaming/jq)
clawler -f jsonl

# Pipe JSONL to jq for custom filtering
clawler -f jsonl | jq 'select(.category == "tech")'

# Same thing with --json-lines alias
clawler --json-lines | jq 'select(.category == "tech")'

# Export current feed list as YAML
clawler --export-feeds my-feeds.yaml

# Atom feed output (subscribe in any feed reader)
clawler -f atom -o feed.xml

# Tech news only, top 20
clawler --category tech -n 20

# Only high-quality sources (score >= 0.75)
clawler --min-quality 0.75

# Security news
clawler --category security

# Skip slow sources
clawler --no-reddit --no-hn

# Skip GitHub Trending
clawler --no-github

# Only articles from last 6 hours
clawler --max-age 6h

# Articles since a specific date (ISO-8601)
clawler --since 2026-02-14

# Articles since a specific datetime
clawler --since 2026-02-14T10:00:00Z

# Custom retry count
clawler --retries 3

# Search for a topic
clawler -s "climate"

# Verbose logging
clawler -v

# List all sources
clawler --list-sources

# Persistent history â€” only show NEW articles since last run (great for cron)
clawler --history

# Custom history window (48 hours)
clawler --history --history-ttl 48h

# Check history stats
clawler --history-stats

# Check feed health
clawler --check-feeds

# Pretty JSON (shorthand for -f json)
clawler --json-pretty

# Dry run â€” see what sources would be crawled
clawler --dry-run

# Group by category
clawler --group-by category

# Group by source
clawler --group-by source

# Reverse sort order (oldest first)
clawler --reverse

# Only stories covered by 2+ sources (trending)
clawler --min-sources 2

# Same thing, shorthand
clawler --trending

# Save results to bookmarks for later
clawler --category tech --bookmark

# List saved bookmarks
clawler --list-bookmarks

# Clear bookmarks
clawler --clear-bookmarks

# Show deduplication statistics
clawler --dedupe-stats

# Remove a specific bookmark by URL
clawler --remove-bookmark "https://example.com/article"

# Count articles only (for scripting)
clawler --category tech --count

# Only show articles older than 12h (stale content analysis)
clawler --stale 12h

# Show article age distribution
clawler --age-distribution

# Use month/year time units
clawler --since 3M
clawler --max-age 1y

# Control summary truncation length
clawler --summary-length 150

# Output just URLs (great for piping to other tools)
clawler --category tech --urls-only

# Output just titles
clawler --titles-only

# Disable deduplication (see all raw articles)
clawler --no-dedup

# Show domain breakdown after output
clawler --domains

# Generate a starter config file
clawler --config-init

# Show per-source health report
clawler --source-health

# Random sample of 10 articles (serendipity mode)
clawler --sample 10

# Compact JSON (single line, great for streaming/logging)
clawler --json-compact

# Disable colors
clawler --no-color

# Configure via environment variables (great for containers)
CLAWLER_CATEGORY=tech CLAWLER_LIMIT=20 clawler

# Only enable specific sources (cleaner than multiple --no-* flags)
clawler --only rss,hn

# Only Hacker News and Reddit
clawler --only hn,reddit

# Pipe-friendly: stderr is auto-suppressed when piped
clawler -f json | jq '.[] | .title'
```

## Sources

| Source | Type | Category | Quality |
|--------|------|----------|---------|
| Reuters | RSS | world | 0.90 |
| BBC News | RSS | world | 0.85 |
| NY Times | RSS | world | 0.84 |
| Nature | RSS | science | 0.84 |
| Bloomberg | RSS | business | 0.83 |
| ProPublica | RSS | investigative | 0.82 |
| Krebs on Security | RSS | security | 0.81 |
| MIT Technology Review | RSS | tech | 0.81 |
| Ars Technica | RSS | tech | 0.81 |
| Schneier on Security | RSS | security | 0.80 |
| Rest of World | RSS | tech | 0.80 |
| NPR | RSS | world | 0.80 |
| The Guardian | RSS | world | 0.80 |
| 404 Media | RSS | tech | 0.79 |
| LWN.net | RSS | tech | 0.78 |
| IEEE Spectrum | RSS | tech | 0.78 |
| Al Jazeera | RSS | world | 0.78 |
| DW | RSS | world | 0.78 |
| The Atlantic | RSS | culture | 0.77 |
| The Conversation | RSS | science | 0.77 |
| Hacker News | API | tech | 0.75 |
| HN Show | RSS | tech | 0.75 |
| HN Ask | RSS | tech | 0.75 |
| ArXiv CS.AI | RSS | science | 0.82 |
| ArXiv CS.LG | RSS | science | 0.82 |
| HN Best | RSS | tech | 0.76 |
| IEEE AI | RSS | tech | 0.78 |
| TorrentFreak | RSS | tech | 0.74 |
| Wired | RSS | tech | 0.73 |
| The Intercept | RSS | investigative | 0.72 |
| TechCrunch | RSS | tech | 0.71 |
| New Scientist | RSS | science | 0.71 |
| Nautilus | RSS | science | 0.71 |
| Lobsters | RSS | tech | 0.70 |
| Phoronix | RSS | tech | 0.70 |
| The Hacker News | RSS | tech | 0.70 |
| TechDirt | RSS | tech | 0.69 |
| ScienceDaily | RSS | science | 0.69 |
| Phys.org | RSS | science | 0.69 |
| EFF Updates | RSS | security | 0.69 |
| The Verge | RSS | tech | 0.68 |
| CNBC | RSS | business | 0.65 |
| CNN | RSS | world | 0.64 |
| Reddit | JSON | various | 0.62 |
| The Next Web | RSS | tech | 0.60 |
| Google News | RSS | world | 0.60 |
| Google News (Tech) | RSS | tech | 0.60 |
| GitHub Trending | Scrape | tech | 0.72 |
| TechMeme | RSS | tech | 0.79 |
| ProductHunt | RSS | tech | 0.66 |

## Quality Weighting

Articles are ranked by a blended score: **60% recency + 40% source quality**.

- **Recency** = `max(0, 1.0 - age_hours / 48)` â€” articles older than 48h get 0
- **Quality** = source score from `source_weights.yaml`, derived from 6 dimensions:
  - Credibility (25%) â€” editorial standards, fact-checking
  - Uniqueness (20%) â€” original reporting vs aggregation
  - Signal-to-noise (20%) â€” substantive content vs filler
  - Freshness (15%) â€” how quickly stories appear
  - Reliability (10%) â€” feed uptime and consistency
  - Coverage (10%) â€” breadth of topics

During deduplication, when the same story appears from multiple sources, the version from the higher-quality source is kept.

## Health Tracking

Clawler tracks per-source health in `~/.clawler/health.json`:

- **total_crawls** â€” number of crawl attempts
- **failures** â€” number of failed crawls
- **avg_articles** â€” average articles per successful crawl
- **last_success** â€” timestamp of last successful crawl

Health modifiers automatically reduce effective quality scores:
- Success rate < 80% â†’ 20% reduction
- Success rate < 50% â†’ 50% reduction

## Architecture

```
clawler/
â”œâ”€â”€ cli.py              # CLI entry point (30+ flags)
â”œâ”€â”€ engine.py           # Crawl orchestrator (parallel + quality scoring)
â”œâ”€â”€ models.py           # Article dataclass (dedup keys, quality_score, relevance)
â”œâ”€â”€ dedup.py            # 3-tier deduplication (quality-aware)
â”œâ”€â”€ weights.py          # Source quality score lookups
â”œâ”€â”€ health.py           # Per-source health tracking
â”œâ”€â”€ source_weights.yaml # Quality scores for all 65+ sources
â”œâ”€â”€ cache.py            # File-based result caching
â”œâ”€â”€ config.py           # Config file support
â”œâ”€â”€ profile.py          # Interest-based relevance scoring
â”œâ”€â”€ discover.py         # Feed autodiscovery
â”œâ”€â”€ opml.py             # OPML import/export
â”œâ”€â”€ bookmarks.py        # Local bookmark management
â”œâ”€â”€ feeds_config.py     # Custom feed file loading
â”œâ”€â”€ utils.py            # Shared utilities
â”œâ”€â”€ sources/            # 12 source types, 65+ individual sources
â”‚   â”œâ”€â”€ base.py         # Abstract base source
â”‚   â”œâ”€â”€ rss.py          # RSS/Atom feed crawler (48 feeds)
â”‚   â”œâ”€â”€ hackernews.py   # HN Firebase API
â”‚   â”œâ”€â”€ reddit.py       # Reddit JSON (5 subreddits)
â”‚   â”œâ”€â”€ github_trending.py # GitHub Trending scraper
â”‚   â”œâ”€â”€ mastodon.py     # Mastodon trending (4 instances)
â”‚   â”œâ”€â”€ lobsters.py     # Lobsters hottest
â”‚   â”œâ”€â”€ wikipedia.py    # Wikipedia Current Events
â”‚   â”œâ”€â”€ devto.py        # Dev.to top articles
â”‚   â”œâ”€â”€ arxiv.py        # ArXiv CS/AI/ML papers
â”‚   â”œâ”€â”€ techmeme.py     # TechMeme curated tech news
â”‚   â”œâ”€â”€ producthunt.py  # ProductHunt trending
â”‚   â”œâ”€â”€ bluesky.py      # Bluesky AT Protocol trending
â”‚   â””â”€â”€ tildes.py       # Tildes community topics
â””â”€â”€ formatters/
    â”œâ”€â”€ console.py      # Rich terminal output
    â”œâ”€â”€ json_out.py     # JSON output
    â”œâ”€â”€ jsonl_out.py    # JSON Lines output (JSONL)
    â”œâ”€â”€ jsonfeed.py     # JSON Feed format
    â”œâ”€â”€ atom.py         # Atom 1.0 feed format
    â”œâ”€â”€ markdown.py     # Markdown output
    â”œâ”€â”€ csv_out.py      # CSV output
    â””â”€â”€ html_out.py     # HTML output
```

## Environment Variables

All CLI flags can be set via `CLAWLER_*` environment variables (CLI flags always win):

| Variable | Example | Equivalent Flag |
|----------|---------|----------------|
| `CLAWLER_CATEGORY` | `tech,science` | `--category tech,science` |
| `CLAWLER_LIMIT` | `25` | `-n 25` |
| `CLAWLER_SINCE` | `6h` | `--since 6h` |
| `CLAWLER_QUIET` | `true` | `--quiet` |
| `CLAWLER_NO_REDDIT` | `1` | `--no-reddit` |
| `CLAWLER_FORMAT` | `json` | `-f json` |
| `CLAWLER_WORKERS` | `4` | `--workers 4` |
| `CLAWLER_DEDUPE_THRESHOLD` | `0.8` | `--dedupe-threshold 0.8` |
| `NO_COLOR` | `1` | `--no-color` |

Priority: CLI flags > environment variables > config files > defaults.

## License

MIT